{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7100516f-d043-4178-8bb6-b4197953bc70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "成功获取第 1 页内容\n",
      "成功获取第 2 页内容\n",
      "成功获取第 3 页内容\n",
      "成功获取第 4 页内容\n",
      "成功获取第 5 页内容\n",
      "成功获取第 6 页内容\n",
      "成功获取第 7 页内容\n",
      "成功获取第 8 页内容\n",
      "成功获取第 9 页内容\n",
      "成功获取第 10 页内容\n",
      "成功获取第 11 页内容\n",
      "成功获取第 12 页内容\n",
      "成功获取第 13 页内容\n",
      "成功获取第 14 页内容\n",
      "成功获取第 15 页内容\n",
      "成功获取第 16 页内容\n",
      "成功获取第 17 页内容\n",
      "成功获取第 18 页内容\n",
      "成功获取第 19 页内容\n",
      "成功获取第 20 页内容\n",
      "CSV 文件已创建: news1.csv\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import csv\n",
    "\n",
    "# 创建一个空列表来存储所有页面的数据\n",
    "total_data = []\n",
    "\n",
    "# 遍历1到20页\n",
    "for page_num in range(1, 21):\n",
    "    url = f'https://finance.sina.com.cn/roll/index.d.html?cid=57084&page={page_num}'\n",
    "    html = requests.get(url)\n",
    "    html.encoding = html.apparent_encoding\n",
    "\n",
    "    if html.status_code == 200:\n",
    "        print(f\"成功获取第 {page_num} 页内容\")\n",
    "\n",
    "        soup = BeautifulSoup(html.text, 'lxml')\n",
    "        # 找到特定的 div 元素\n",
    "        div_element = soup.find('div', id='Main')\n",
    "\n",
    "        # 找到 div 元素下的所有 ul 元素\n",
    "        ul_elements = div_element.find_all('ul') if div_element else []\n",
    "\n",
    "        # 创建一个空列表来存储收集到的 <li> 元素的文本内容\n",
    "        li_texts = []\n",
    "\n",
    "        # 遍历每个 ul 元素下的所有 li 元素的文本内容\n",
    "        for ul in ul_elements:\n",
    "            li_elements = ul.find_all('li') if ul else []\n",
    "            for li in li_elements:\n",
    "                if li is not None:\n",
    "                    li_texts.append(li.text.strip())\n",
    "\n",
    "        # 创建一个空列表来存储标题和时间信息\n",
    "        data = []\n",
    "\n",
    "        # 遍历每个收集到的 <li> 元素的文本内容\n",
    "        for sentence in li_texts:\n",
    "            # 使用正则表达式匹配标题和时间\n",
    "            match = re.search(r'^(.*?)\\((\\d{2}月\\d{2}日 \\d{2}:\\d{2})\\)', sentence)\n",
    "\n",
    "            if match:\n",
    "                title = match.group(1).strip()  # 提取标题并去除首尾空格\n",
    "                time = match.group(2)  # 提取时间\n",
    "                # 将标题和时间信息添加到数据列表中\n",
    "                data.append([title, time])\n",
    "\n",
    "        # 将当前页面的数据添加到总数据列表中\n",
    "        total_data.extend(data)\n",
    "    else:\n",
    "        print(f'页面 {page_num} 请求出错')\n",
    "\n",
    "# 指定 CSV 文件名\n",
    "csv_file = \"news1.csv\"\n",
    "\n",
    "# 将数据写入 CSV 文件\n",
    "with open(csv_file, 'w', newline='', encoding='utf-8') as f:\n",
    "    # 创建 CSV writer 对象\n",
    "    writer = csv.writer(f)\n",
    "    # 写入标题行\n",
    "    writer.writerow(['title', 'time'])\n",
    "    # 写入数据\n",
    "    writer.writerows(total_data)\n",
    "\n",
    "print(\"CSV 文件已创建:\", csv_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4cec4d93-ffe4-44f7-9242-ec3c496a85cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      title               time\n",
      "0        美国就业失业双升，降息预期升还是降？  2024年06月08日 21:00\n",
      "1       美国5月非农就业：多年来最诡异的一次？  2024年06月08日 20:00\n",
      "2   重磅数据发布，金价突然大跌！美联储降息又悬了？  2024年06月08日 18:15\n",
      "3  美国非农强劲、中国央行停买，黄金遭“双重打击”！  2024年06月08日 11:39\n",
      "4  一觉醒来 国际贵金属期货集体暴跌！又一次见证历史  2024年06月08日 08:14\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 加载 CSV 文件\n",
    "df = pd.read_csv(r\"C:\\Users\\22375\\news1.csv\",encoding='utf-8')\n",
    "\n",
    "\n",
    "# 将时间列转换为日期时间格式，使用自定义的日期时间格式\n",
    "df['time'] = pd.to_datetime(df['time'], format='%m月%d日 %H:%M')\n",
    "\n",
    "# 添加“2024年”并转换为字符串格式\n",
    "df['time'] = '2024年' + df['time'].dt.strftime('%m月%d日 %H:%M')\n",
    "\n",
    "# 保存修改后的 DataFrame 到新的 CSV 文件\n",
    "df.to_csv('modified_file.csv', index=False)\n",
    "\n",
    "# 显示修改后的 DataFrame 的前几行\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b80247b6-6896-4dff-9fba-31098f0caf9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('news1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "628ddd33-cf40-40e7-8e81-feb517a12cfa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a24c9da-4180-447f-9854-9884875783e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
